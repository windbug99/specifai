# Claude Project - Specifai 서비스기획 개선 가이드

## 📋 프로젝트 개요

Specifai는 **AI-Native 요구사항명세서 자동 생성 플랫폼**입니다. 
이 프로젝트는 소규모 IT 프로젝트 시장(1인 개발자, 프리랜서)의 커뮤니케이션 문제를 해결합니다.

### 핵심 가치
- **분쟁 방지**: 명확한 범위 설정으로 외주 분쟁 80% 감소
- **시간 절약**: 명세서 작성 시간 70% 단축
- **AI 최적화**: AI 코딩 도구(Cursor, Claude) 재시도 5회 → 1회
- **AI 에이전트 준비**: 명확한 명세서로 미래의 AI 에이전트 자동 개발 가능

---

## 🎯 Claude Project의 역할

Claude Project는 다음 작업을 수행합니다:

### 1️⃣ 서비스기획 검증 및 개선
- 기획서의 논리적 일관성 검토
- 타겟 고객 정의의 명확성 검증
- 핵심 가치 제안의 설득력 평가
- 시장 분석의 데이터 기반성 검토

### 2️⃣ 핵심기술 검증
- AI-Native 명세서 생성 알고리즘 설계 검증
- AI Instruction Prompt 생성 로직 설계
- 명확성 점수 계산 메트릭 개발
- 기술 스택 선택의 타당성 검토

### 3️⃣ 마켓 피드백 반영
- 타겟 고객 페르소나 개선
- 경쟁사 분석 강화
- 가격 전략 최적화
- GTM(Go-To-Market) 전략 개선

### 4️⃣ 비즈니스 모델 최적화
- 수익 모델의 지속가능성 검토
- Unit Economics 분석
- CAC/LTV 최적화 전략
- Scale Path 명확화

---

## 📁 프로젝트 문서 구조

```
docs/
├── 01_overview.md                    # 서비스 개요, 미션, 타겟, 가치제안
├── 02_background_and_problems.md     # 시장 문제, AI 시대의 변화
├── 03_market_analysis.md             # 시장 규모, 경쟁, 트렌드
├── 04_product_features.md            # 핵심 기능, 차별화 포인트
├── 05_moat_strategy.md               # 4단계 해자 구축 전략
├── 06_business_model.md              # 수익 모델, 가격, 재무
├── 07_development_plan.md            # 6주 MVP, 개발 계획, 마케팅
├── 08_risk_management.md             # 리스크, 중단 기준, 피벗 옵션
├── 09_success_metrics.md             # KPI, 성공 지표
├── 10_conclusion.md                  # 실행 계획, 체크리스트
├── README.md                         # 프로젝트 요약
└── CLAUDE_PROJECT_INSTRUCTIONS.md    # 이 파일
```

---

## 🔍 핵심 검증 영역

### A. 서비스 포지셔닝 검증

#### ✅ 검증할 사항
1. **타겟 고객 명확성**
   - 1차 타겟: 1인 개발자, 프리랜서 (소규모 프로젝트)
   - 2차 타겟: 소규모 팀/스타트업 (향후 확장)
   - 피드백: 타겟의 구체적 페인포인트가 명확한가?

2. **차별화 포인트**
   - AI-Native Instruction Prompt 자동 생성
   - 외주 특화 (vs 범용 도구)
   - 한국 시장 최적화
   - 질문: 경쟁사와의 차이가 충분히 명확한가?

3. **시장 타이밍**
   - AI 코딩 도구 폭발적 성장 (Cursor, Claude)
   - 프리랜서 경제 확산
   - 조직 구조의 소형화
   - 질문: 이 타이밍이 정말 최적인가?

#### 📝 개선 요청 방식
```
"Specifai의 타겟 고객(1인 개발자, 프리랜서)의 페인포인트를 더 구체적으로 
정의할 수 있나요? 현재 기획에서 부족한 부분이 있는지 검토해 주세요."
```

---

### B. 핵심기술 검증

#### ✅ 검증할 사항

1. **AI-Native 명세서 생성 알고리즘**
   ```
   입력: 사용자의 자유로운 답변
   → 질문 기반 구조화
   → 일관성 검증
   → 누락 항목 감지
   → AI-Native 명세서 생성
   출력: Markdown 형식 명세서
   ```
   
   검증 질문:
   - 50-100개 질문으로 충분한가?
   - 질문의 계층 구조가 적절한가?
   - 각 답변의 일관성을 어떻게 검증할 것인가?

2. **AI Instruction Prompt 생성 로직**
   ```
   입력: 생성된 명세서
   → Cursor/Claude 포맷 변환
   → 기술 스택 최적화
   → 구현 가이드 추가
   출력: 1,000-2,000줄 상세 프롬프트
   ```
   
   검증 질문:
   - AI 도구별 최적화 포맷 차이는?
   - BDD 형식(Given/When/Then)을 어떻게 적용할 것인가?
   - 성능 요구사항은 어떻게 표현할 것인가?

3. **명확성 점수 계산**
   ```
   입력: 명세서
   → 모호한 표현 탐지
   → 구체성 점수 계산
   → AI 이해도 점수
   → 에이전트 준비도 평가
   출력: 0-100 명확성 점수
   ```
   
   검증 질문:
   - 명확성을 어떤 지표로 측정할 것인가?
   - 각 지표의 가중치는 어떻게 설정할 것인가?
   - 점수와 실제 AI 성능의 상관관계는?

---

### C. 비즈니스 모델 검증

#### ✅ 검증할 사항

1. **가격 전략**
   - Personal: 5만원/명세서
   - Freelancer: 20만원/월
   - Business: 50만원/월
   - Enterprise: 100만원+/월
   
   검증 질문:
   - 타겟층별 가격 수용도는?
   - 경쟁사(ChatGPT, 위시켓) 대비 적정한가?
   - 가격 민감도 조사 필요한가?

2. **Unit Economics**
   ```
   목표:
   - CAC < LTV/3
   - Payback Period < 3개월
   - Gross Margin > 80%
   ```
   
   검증 질문:
   - 초기 CAC는 얼마로 예상하는가?
   - 장기 LTV는 어떻게 계산되는가?
   - 구독 vs 건당 수익의 비율은?

3. **Scale Path**
   - Phase 1: 소규모 프로젝트 시장 (1인 개발자, 프리랜서)
   - Phase 2: 소규모 팀 (스타트업, 소기업)
   - Phase 3: 규모있는 기업 팀
   
   검증 질문:
   - 각 Phase의 시간 제약은?
   - 기능은 어떻게 다를 것인가?
   - 마케팅 채널은 어떻게 변할 것인가?

---

### D. 시장 분석 검증

#### ✅ 검증할 사항

1. **TAM (Total Addressable Market)**
   - 현재: 1.6조원 (소규모 프로젝트)
   - 방법: 한국 IT 외주 시장 × 소규모 프로젝트 비율
   
   검증 질문:
   - 이 숫자의 데이터 출처는?
   - 실제 소규모 프로젝트 비율은 얼마인가?
   - 보수적 추정인가, 낙관적 추정인가?

2. **경쟁 분석**
   - 직접 경쟁: 없음 (외주 특화 명세서 도구)
   - 간접 경쟁: ChatGPT, 위시켓, 이랜서
   
   검증 질문:
   - 정말 직접 경쟁자가 없는가?
   - 간접 경쟁자의 강점은?
   - 우리의 차별화 포인트는 방어 가능한가?

3. **마켓 트렌드**
   - 프리랜서 경제 성장
   - AI 코딩 도구 급성장
   - 조직 구조의 소형화
   
   검증 질문:
   - 이 트렌드들이 지속될 것인가?
   - 반대 트렌드는 없는가?
   - 우리 비즈니스에 미치는 영향은?

---

## 💬 질문 가이드

Claude Project와 대화할 때 다음 형식으로 질문하세요:

### 형식 1: 특정 문서 개선
```
"[문서명]의 [섹션]을 검토해 주세요. 
현재 상황: [현재 내용 요약]
문제점: [느껴지는 문제]
기대 결과: [어떻게 개선되길 원하는가]"
```

**예시:**
```
"03_market_analysis.md의 TAM 계산을 검토해 주세요.
현재 상황: 한국 IT 외주 시장 5조원에서 소규모 프로젝트 비율로 1.6조원 계산
문제점: 소규모 프로젝트 비율의 데이터 출처가 불명확함
기대 결과: 더 명확한 데이터 기반의 TAM 계산 또는 보수적 범위 제시"
```

### 형식 2: 핵심기술 설계 검증
```
"다음 기술 설계를 검토해 주세요:
[기술 설명]

검증 항목:
1. [항목1]
2. [항목2]
3. [항목3]"
```

**예시:**
```
"AI-Native 명세서 생성 알고리즘을 검토해 주세요:
1. 50-100개 동적 질문으로 요구사항 수집
2. 사용자 답변의 일관성 자동 검증
3. 누락된 항목 감지 및 추가 질문 생성
4. 최종 명세서 자동 생성 (Markdown)

검증 항목:
1. 이 알고리즘으로 충분히 명확한 명세서가 생성될까?
2. 각 단계의 구현 복잡도는?
3. 실제 사용 사례에서 작동하는가?"
```

### 형식 3: 비교 분석 요청
```
"[항목1]과 [항목2]를 비교하고 최선의 선택을 제안해 주세요.

Context:
[상황 설명]

비교 항목:
- [항목1]: [설명]
- [항목2]: [설명]"
```

**예시:**
```
"구독 모델(Freelancer: 20만원/월)과 건당 결제(명세서: 5만원)을 비교해 주세요.

Context:
1인 개발자, 프리랜서가 주요 타겟이며, 월 사용 빈도는 불명확함

비교 항목:
- 구독 모델: 안정적 매출, 높은 LTV
- 건당 결제: 낮은 초기 장벽, 변동성 수익"
```

---

## 🎬 대화 시작 템플릿

### Session 1: 전체 기획 검토
```
Specifai 서비스기획서를 전반적으로 검토해 주세요.

주요 질문:
1. 서비스 포지셔닝: 타겟(1인 개발자, 프리랜서) 정의가 명확한가?
2. 차별화: "AI-Native Instruction Prompt"가 충분히 설득력 있는가?
3. 시장: 1.6조원 TAM 추정이 합리적인가?
4. 비즈니스: 가격 전략과 Unit Economics가 타당한가?
5. 실행: MVP 6주 계획이 현실적인가?

각 항목에 대해 강점과 개선점을 명시해 주세요.
```

### Session 2: 핵심기술 설계
```
Specifai의 핵심기술 3가지를 설계하고 검증해 주세요:

1. AI-Native 명세서 생성 엔진
   - 입력: 사용자 답변
   - 출력: 논리적이고 명확한 명세서
   - 검증: 실제 작동 가능한가?

2. AI Instruction Prompt 생성 로직
   - 입력: 생성된 명세서
   - 출력: Cursor/Claude용 1,000줄 프롬프트
   - 검증: 포맷과 최적화 전략은?

3. 명확성 점수 계산 메트릭
   - 입력: 명세서
   - 출력: 0-100 점수
   - 검증: 측정 방식과 신뢰도는?

각 기술에 대해 알고리즘, 구현 방식, 검증 방법을 제시해 주세요.
```

### Session 3: 비즈니스 모델 최적화
```
Specifai의 비즈니스 모델을 최적화해 주세요.

현재 모델:
- Personal: 5만원/명세서
- Freelancer: 20만원/월
- Business: 50만원/월
- Enterprise: 100만원+/월

분석 요청:
1. 타겟층별 가격 수용도는 얼마인가?
2. Unit Economics (CAC, LTV, Payback)는?
3. 초기 MAU와 전환율 목표는?
4. 가격 A/B 테스트 전략은?
5. 대체 수익 모델이 있는가?

데이터 기반의 개선안을 제시해 주세요.
```

### Session 4: GTM (Go-To-Market) 전략
```
Specifai의 GTM 전략을 개선해 주세요.

현재 계획:
- Phase 1: 개발자 커뮤니티, 기술 블로그, GeekNews
- Phase 2: 프리랜서 플랫폼 통합
- Phase 3: B2B 기업 세일즈

개선 요청:
1. Week 1-3 베타 모집 전략은 현실적인가?
2. 각 채널별 기대 효과는?
3. 병렬 마케팅 전략이 필요한가?
4. 초기 고객 확보 기준은?
5. 피벗 시나리오는 충분한가?

구체적인 액션 플랜을 제시해 주세요.
```

---

## 📊 피드백 반영 체크리스트

Claude Project와의 대화 후, 다음 사항을 확인하세요:

### 1️⃣ 피드백 수집
- [ ] 서비스 포지셔닝 피드백
- [ ] 핵심기술 설계 피드백
- [ ] 비즈니스 모델 피드백
- [ ] GTM 전략 피드백

### 2️⃣ 기획서 업데이트
- [ ] 강점/약점 명시
- [ ] 데이터 기반 근거 추가
- [ ] 실행 계획 구체화
- [ ] 리스크 및 대응책 추가

### 3️⃣ 미해결 항목
- [ ] 추가 검증 필요한 항목
- [ ] 정보 부족한 항목
- [ ] 시장 조사 필요한 항목
- [ ] 기술 검증 필요한 항목

---

## 🚀 다음 단계

### After Claude Project 검토:
1. **기획서 개선** - 피드백 반영하여 기획서 개선
2. **핵심기술 검증** - Claude Code에서 프로토타입 개발
3. **실제 구축** - 개발 도구(Cursor, VS Code)에서 MVP 개발
4. **베타 테스트** - 실제 타겟 사용자와 검증

### 예상 일정:
- Week 1-2: Claude Project 검토 및 기획서 개선
- Week 3-4: Claude Code 핵심기술 검증
- Week 5-10: Cursor/개발 도구로 MVP 구축
- Week 11-12: 베타 테스트 및 피드백 수집

---

## 💡 팁

1. **구체적인 질문하기**
   - ❌ "이거 좋은가요?"
   - ✅ "이 가격 전략이 1인 개발자 타겟층에 적정한가?"

2. **문맥 제공하기**
   - 현재 상황, 가정, 목표를 명확히 제시
   - 관련 문서 섹션 인용

3. **반복적 개선**
   - 한 번에 완벽한 답을 기대하기보다
   - 여러 라운드의 대화로 점진적 개선

4. **데이터 기반 논의**
   - 추측보다는 데이터와 사례 활용
   - 불확실한 부분은 명시

---

## 📞 연락처 및 문서

- **프로젝트**: Specifai
- **목표**: AI-Native 요구사항명세서 자동 생성 플랫폼
- **타겟**: 1인 개발자, 프리랜서 (소규모 프로젝트 시장)
- **기획서**: `/Users/tomato/cursor/specifai/docs/`

---

**"명확한 소통은 모든 프로젝트의 시작이다. Specifai는 그 시작을 도와준다."**
